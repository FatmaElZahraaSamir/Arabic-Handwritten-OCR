{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Arabic Handwritten Characters Recognition\n#### In this project we will employ deep learning model to classify the images to an arabic letter.\n\n## Dataset\n#### The dataset for this project originates from kaggle kernels which include [Arabic Letters](http://https://www.kaggle.com/mloey1/ahcd1).\n#### All the datasets are CSV files representing the image pixels values and their corresponding label.\n\n**Arabic Letters Dataset is composed of 16,800 characters written by 60 participants,** the age range is between 19 to 40 years, and 90% of participants are right-hand. Each participant wrote each character (from 'alef' to 'yeh') ten times. The images were scanned at the resolution of 300 dpi. Each block is segmented automatically using Matlab 2016a to determining the coordinates for each block. **The dataset is partitioned into two sets: a training set of 13,440 characters to 480 images per class and a test set of 3,360 characters to 120 images per class.** Writers of training set and test set are exclusive. Ordering of including writers to test set are randomized to make sure that writers of test set are not from a single institution to ensure variability of the test set.\n\n\n## Data Exploration\n#### Import libraries necessary for this project.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import main libraries necessary for this project\nimport numpy as np\nimport pandas as pd\nfrom IPython.display import display # Allows the use of display() for DataFrames\n\n# Import libraries needed for reading image and processing it\nimport csv\nfrom PIL import Image\nfrom scipy.ndimage import rotate\n\n# Pretty display for notebooks\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Load Arabic Letters dataset files into dataframes"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training letters images and labels files\nletters_training_images_file_path = \"../input/ahcd1/csvTrainImages 13440x1024.csv\"\nletters_training_labels_file_path = \"../input/ahcd1/csvTrainLabel 13440x1.csv\"\n# Testing letters images and labels files\nletters_testing_images_file_path = \"../input/ahcd1/csvTestImages 3360x1024.csv\"\nletters_testing_labels_file_path = \"../input/ahcd1/csvTestLabel 3360x1.csv\"\n\n# Loading dataset into dataframes\ntraining_letters_images = pd.read_csv(letters_training_images_file_path, header=None)\ntraining_letters_labels = pd.read_csv(letters_training_labels_file_path, header=None)\ntesting_letters_images = pd.read_csv(letters_testing_images_file_path, header=None)\ntesting_letters_labels = pd.read_csv(letters_testing_labels_file_path, header=None)\n\n# print statistics about the dataset\nprint(\"There are %d training arabic letter images of 32x32 pixels.\" %training_letters_images.shape[0])\nprint(\"There are %d testing arabic letter images of 32x32 pixels.\" %testing_letters_images.shape[0])\ntraining_letters_images.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Convert csv values to an image\nWritting a method to be used later if we want visualization of an image from its pixels values."},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_values_to_image(image_values, display=False):\n    image_array = np.asarray(image_values)\n    image_array = image_array.reshape(32,32).astype('uint8')\n    # The original dataset is reflected so we will flip it then rotate for a better view only.\n    image_array = np.flip(image_array, 0)\n    image_array = rotate(image_array, -90)\n    new_image = Image.fromarray(image_array)\n    if display == True:\n        new_image.show()\n    return new_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"convert_values_to_image(training_letters_images.loc[0], True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing\n### Image Normalization <br/>\n**We rescale the images by dividing every pixel in the image by 255 to make them into range [0, 1]"},{"metadata":{"trusted":true},"cell_type":"code","source":"training_letters_images_scaled = training_letters_images.values.astype('float32')/255\ntraining_letters_labels = training_letters_labels.values.astype('int32')\ntesting_letters_images_scaled = testing_letters_images.values.astype('float32')/255\ntesting_letters_labels = testing_letters_labels.values.astype('int32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Training images of letters after scaling\")\nprint(training_letters_images_scaled.shape)\ntraining_letters_images_scaled[0:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Encoding Categorical Labels\n#### From the labels csv files we can see that labels are categorical values and it is a multi-class classification problem.\n**the outputs are in the form of:\nLetters from 'alef' to 'yeh' have categories numbers from 0 to 27**<br/>\n### Here we will encode these categories values using One Hot Encoding with keras.\n\nOne-hot encoding transforms integer to a binary matrix where the array contains only one ‘1’ and the rest elements are ‘0’."},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\n\n# one hot encoding\n# number of classes = 28 (arabic alphabet classes)\nnumber_of_classes = 28\n\ntraining_letters_labels_encoded = to_categorical(training_letters_labels-1, num_classes=number_of_classes)\ntesting_letters_labels_encoded = to_categorical(testing_letters_labels-1, num_classes=number_of_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(training_letters_labels_encoded)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reshaping Input Images to 32x32x1\nWhen using TensorFlow as backend, Keras CNNs require a 4D array (which we'll also refer to as a 4D tensor) as input, with shape (nb_samples,rows,columns,channels)\n\nwhere nb_samples corresponds to the total number of images (or samples), and rows, columns, and channels correspond to the number of rows, columns, and channels for each image, respectively.\n\nSo we will reshape the input images to a 4D tensor with shape (nb_samples, 32, 32 ,1) as we use grayscale images of 32x32 pixels."},{"metadata":{"trusted":true},"cell_type":"code","source":"# reshape input letter images to 32x32x1\ntraining_letters_images_scaled = training_letters_images_scaled.reshape([-1, 32, 32, 1])\ntesting_letters_images_scaled = testing_letters_images_scaled.reshape([-1, 32, 32, 1])\n\nprint(training_letters_images_scaled.shape, training_letters_labels_encoded.shape, testing_letters_images_scaled.shape, testing_letters_labels_encoded.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Designing Model Architecture"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Dropout, Dense\n\ndef create_model(optimizer='adam', kernel_initializer='he_normal', activation='relu'):\n    # create model\n    model = Sequential()\n    model.add(Conv2D(filters=16, kernel_size=3, padding='same', input_shape=(32, 32, 1), kernel_initializer=kernel_initializer, activation=activation))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=2))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(filters=32, kernel_size=3, padding='same', kernel_initializer=kernel_initializer, activation=activation))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=2))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(filters=64, kernel_size=3, padding='same', kernel_initializer=kernel_initializer, activation=activation))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=2))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(filters=128, kernel_size=3, padding='same', kernel_initializer=kernel_initializer, activation=activation))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=2))\n    model.add(Dropout(0.2))\n    model.add(GlobalAveragePooling2D())\n\n    #Fully connected final layer\n    model.add(Dense(28, activation='softmax'))\n\n    # Compile model\n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**above code step by step.**\n\n* The first hidden layer is a convolutional layer. The layer has 16 feature maps, which with the size of 3×3 and an activation function which is relu. This is the input layer, expecting images with the structure outlined above.\n* The second layer is Batch Normalization which solves having distributions of the features vary across the training and test data, which breaks the IID assumption. We use it to help in two ways faster learning and higher overall accuracy.\n* The third layer is the MaxPooling layer. MaxPooling layer is used to down-sample the input to enable the model to make assumptions about the features so as to reduce overfitting. It also reduces the number of parameters to learn, reducing the training time.\n* The next layer is a Regularization layer using dropout. It is configured to randomly exclude 20% of neurons in the layer in order to reduce overfitting.\n* Another hidden layer with 32 feature maps with the size of 3×3 and a relu activation function to capture more features from the image.\n* Other hidden layers with 64 and 128 feature maps with the size of 3×3 and a relu activation function to capture complex patterns from the image which will decribe the digits and letters later.\n* More MaxPooling, Batch Normalization, Regularization and GlobalAveragePooling2D layers.\n* The last layer is the output layer with (number of output classes) and it uses softmax activation function as we have multi-classes. Each neuron will give the probability of that class.\n* I used categorical_crossentropy as a loss function because its a multi-class classification problem. I used accuracy as metrics to improve the performance of our neural network."},{"metadata":{},"cell_type":"markdown","source":"## Model Summary And Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = create_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Keras support plotting the model in keras.utils.vis_utils module which provides utility functions to plot a Keras model using graphviz.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pydot\nfrom keras.utils import plot_model\n\nplot_model(model, to_file=\"model.png\", show_shapes=True)\nfrom IPython.display import Image as IPythonImage\ndisplay(IPythonImage('model.png'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Parameters Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"# fix random seed for reproducibility\nseed = 7\nnp.random.seed(seed)\n\n# define the grid search parameters\noptimizer = ['RMSprop', 'Adam', 'Adagrad', 'Nadam']\nkernel_initializer = ['normal', 'uniform']\nactivation = ['relu', 'linear', 'tanh']\n\nparam_grid = dict(optimizer=optimizer, kernel_initializer=kernel_initializer, activation=activation)\n\n# count number of different parameters values combinations\nparameters_number = 1\nfor x in param_grid:\n    parameters_number = parameters_number * len(param_grid[x]) \nprint(\"Number of different parameter combinations = {}\".format(parameters_number))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We will try different models with different parameters to find the best parameter values.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 5\nbatch_size = 20 # 20 divides the training data samples\n\n#creating the models with different hyperparameters\nfor a,b,c in [(x,y,z) for x in optimizer for z in activation for y in kernel_initializer]:\n    params = {'optimizer' : a , 'kernel_initializer' : b , 'activation' : c}\n    print(params)\n    curr_model = create_model(a, b, c)\n    curr_model.fit(training_letters_images_scaled, training_letters_labels_encoded, \n                    validation_data=(testing_letters_images_scaled, testing_letters_labels_encoded),\n                    epochs=epochs, batch_size=batch_size, verbose=1)\n    print(\"=============================================================================\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<strong>From the above results we can see that best parameters are:\n* Optimizer: Adam\n* Kernel_initializer: uniform\n* Activation: relu\n</strong>\n<br/>\nLet's create the model with the best parameters obtained."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = create_model(optimizer='Adam', kernel_initializer='uniform', activation='relu')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training the Model\n### Fitting the Model\n<strong>Train the model using batch_size=30 to reduce used memory and make the training more quick. We will train the model first on 15 epochs to see the accuracy that we will obtain</strong>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint  \n\n# using checkpoints to save model weights to be used later instead of training again on the same epochs.\ncheckpointer = ModelCheckpoint(filepath='weights.hdf5', verbose=1, save_best_only=True)\nhistory = model.fit(training_letters_images_scaled, training_letters_labels_encoded, \n                    validation_data=(testing_letters_images_scaled, testing_letters_labels_encoded),\n                    epochs=15, batch_size=20, verbose=1, callbacks=[checkpointer])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plotting Loss and Accuracy Curves with Epochs"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_loss_accuracy(history):\n    # Loss Curves\n    plt.figure(figsize=[8,6])\n    plt.plot(history.history['loss'],'r',linewidth=3.0)\n    plt.plot(history.history['val_loss'],'b',linewidth=3.0)\n    plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n    plt.xlabel('Epochs ',fontsize=16)\n    plt.ylabel('Loss',fontsize=16)\n    plt.title('Loss Curves',fontsize=16)\n\n    # Accuracy Curves\n    plt.figure(figsize=[8,6])\n    plt.plot(history.history['accuracy'],'r',linewidth=3.0)\n    plt.plot(history.history['val_accuracy'],'b',linewidth=3.0)\n    plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n    plt.xlabel('Epochs ',fontsize=16)\n    plt.ylabel('Accuracy',fontsize=16)\n    plt.title('Accuracy Curves',fontsize=16) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_loss_accuracy(history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load the Model with the Best Validation Loss"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('weights.hdf5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Final evaluation of the model\nmetrics = model.evaluate(testing_letters_images_scaled, testing_letters_labels_encoded, verbose=1)\nprint(\"Test Accuracy: {}\".format(metrics[1]))\nprint(\"Test Loss: {}\".format(metrics[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We get test accuracy of 95.14% after training on 10 epochs only\n\n#### What about increasing the epochs we train on ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 30\nbatch_size = 20\n\ncheckpointer = ModelCheckpoint(filepath='weights.hdf5', verbose=1, save_best_only=True)\n\nhistory = model.fit(training_letters_images_scaled, training_letters_labels_encoded, \n                    validation_data=(testing_letters_images_scaled, testing_letters_labels_encoded),\n                    epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[checkpointer])\n          \nmodel.load_weights('weights.hdf5')\nplot_loss_accuracy(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_loss_accuracy(history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Testing the Model again"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Final evaluation of the model\nmetrics = model.evaluate(testing_letters_images_scaled, testing_letters_labels_encoded, verbose=1)\nprint(\"Test Accuracy: {}\".format(metrics[1]))\nprint(\"Test Loss: {}\".format(metrics[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After training the model on more epochs we gained a better model which can classify complex patterns. So when we tested it on our test dataset we had better results than before.\n\n**Test accuracy is improved from 95.14% to 97.47% As we train the model on 20 more epochs.**"},{"metadata":{},"cell_type":"markdown","source":"## Saving the Final Model\n#### Let's save the model on json format to be used later instead of creating the model again from scratch."},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import model_from_yaml\nmodel_yaml = model.to_yaml()\nwith open(\"model.yaml\", \"w\") as yaml_file:\n    yaml_file.write(model_yaml)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Save the model weights to file."},{"metadata":{"trusted":true},"cell_type":"code","source":"# serialize weights to HDF5\nmodel.save_weights(\"model.h5\")\nprint(\"Saved model to disk\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### if we want to load the model with the last obtained weights at anytime, we will run the following code cell."},{"metadata":{"trusted":true},"cell_type":"code","source":"# load YAML and create model\nyaml_file = open('model.yaml', 'r')\nloaded_model_yaml = yaml_file.read()\nyaml_file.close()\nloaded_model = model_from_yaml(loaded_model_yaml)\n# load weights into new model\nloaded_model.load_weights(\"model.h5\")\nprint(\"Loaded model from disk\")\n \n# compile the loaded model\nloaded_model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict Image Classes\n<strong>Making a method which takes a model, data and its true labels (optional for using in testing). Then it gives the predicted classes of the given data using the given model.</strong>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_predicted_classes(model, data, labels=None):\n    image_predictions = model.predict(data)\n    predicted_classes = np.argmax(image_predictions, axis=1)\n    true_classes = np.argmax(labels, axis=1)\n    return predicted_classes, true_classes, image_predictions","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Making a method which will print all metrics (precision, recall, f1-score and support) with each class in the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ndef get_classification_report(y_true, y_pred):\n    print(classification_report(y_true, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred, y_true, image_predictions = get_predicted_classes(model, testing_letters_images_scaled, testing_letters_labels_encoded)\nget_classification_report(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"errors = (y_pred - y_true != 0)\n\n\nY_pred_classes_errors = y_pred[errors]\nY_pred_errors = image_predictions[errors]\nY_true_errors = y_true[errors]\nX_val_errors = testing_letters_images_scaled[errors]\n\n\ndef display_errors(errors_index,img_errors,pred_errors, obs_errors):\n    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n    n = 0\n    nrows = 2\n    ncols = 3\n    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n    for row in range(nrows):\n        for col in range(ncols):\n            error = errors_index[n]\n            image_array = np.flip(img_errors[error], 0)\n            image_array = rotate(img_errors[error], -90)\n            ax[row,col].imshow((image_array).reshape((32,32)))\n            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n            n += 1\n\n# Probabilities of the wrong predicted letters\nY_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n\n# Predicted probabilities of the true values in the error set\ntrue_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n\n# Difference between the probability of the predicted label and the true label\ndelta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n\n# Sorted list of the delta prob errors\nsorted_dela_errors = np.argsort(delta_pred_true_errors)\n\n# Top 6 errors \nmost_important_errors = sorted_dela_errors[-6:]\n\n# Show the top 6 errors\ndisplay_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}